{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SIKU-BERT/sikubert\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>word_seg1</th>\n",
       "      <th>word_seg2</th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>岁通盛世家家富</td>\n",
       "      <td>人遇年华个个欢</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1]</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1]</td>\n",
       "      <td>[11, 11, 7, 11, 7, 7]</td>\n",
       "      <td>[7, 15, 15, 7, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>森林繁茂生梁栋</td>\n",
       "      <td>大海深沉蕴宝珍</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[7, 7, 0, 0, 15, 11]</td>\n",
       "      <td>[7, 7, 0, 0, 15, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>换个角度看世界</td>\n",
       "      <td>留些空间还中国</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[15, 7, 7, 7, 15, 7]</td>\n",
       "      <td>[15, 0, 7, 7, 15, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>崛起新村莺燕舞</td>\n",
       "      <td>腾飞伟业凤龙来</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 1]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 1]</td>\n",
       "      <td>[15, 15, 7, 7, 7, 7]</td>\n",
       "      <td>[11, 15, 7, 7, 11, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>一湖芳树洇诗绿</td>\n",
       "      <td>万簇鲜花沁画红</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[8, 7, 7, 7, 11, 11]</td>\n",
       "      <td>[8, 7, 7, 7, 15, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>1</td>\n",
       "      <td>胸中块垒最添堵</td>\n",
       "      <td>眼下风光正入时</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[7, 7, 7, 7, 2, 0]</td>\n",
       "      <td>[7, 7, 7, 7, 2, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>0</td>\n",
       "      <td>不愿折腰求寸进</td>\n",
       "      <td>杨柳屯前劳燕分</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 1]</td>\n",
       "      <td>[3, 3, 15, 15, 15, 15]</td>\n",
       "      <td>[11, 11, 9, 7, 15, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>1</td>\n",
       "      <td>丑角登台添笑料</td>\n",
       "      <td>时髦抢眼挺风流</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[7, 7, 15, 15, 15, 7]</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>1</td>\n",
       "      <td>雨打芳林花溅泪</td>\n",
       "      <td>风吹古柏树参天</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 0]</td>\n",
       "      <td>[15, 15, 7, 7, 7, 15]</td>\n",
       "      <td>[7, 15, 7, 7, 7, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>0</td>\n",
       "      <td>兰草絮语堪留醉</td>\n",
       "      <td>花铺地毯秀娇容</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[7, 7, 7, 7, 15, 15]</td>\n",
       "      <td>[7, 15, 7, 7, 15, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label    text1    text2              word_seg1              word_seg2  \\\n",
       "0           1  岁通盛世家家富  人遇年华个个欢  [1, 1, 1, 0, 1, 0, 1]  [1, 1, 1, 0, 1, 0, 1]   \n",
       "1           1  森林繁茂生梁栋  大海深沉蕴宝珍  [1, 0, 1, 0, 1, 1, 0]  [1, 0, 1, 0, 1, 1, 0]   \n",
       "2           1  换个角度看世界  留些空间还中国  [1, 1, 1, 0, 1, 1, 0]  [1, 1, 1, 0, 1, 1, 0]   \n",
       "3           1  崛起新村莺燕舞  腾飞伟业凤龙来  [1, 0, 1, 0, 1, 0, 1]  [1, 0, 1, 0, 1, 0, 1]   \n",
       "4           1  一湖芳树洇诗绿  万簇鲜花沁画红  [1, 1, 1, 0, 1, 1, 1]  [1, 1, 1, 0, 1, 1, 1]   \n",
       "...       ...      ...      ...                    ...                    ...   \n",
       "159995      1  胸中块垒最添堵  眼下风光正入时  [1, 0, 1, 0, 1, 1, 1]  [1, 0, 1, 0, 1, 1, 1]   \n",
       "159996      0  不愿折腰求寸进  杨柳屯前劳燕分  [1, 1, 1, 0, 0, 0, 0]  [1, 0, 0, 1, 0, 0, 1]   \n",
       "159997      1  丑角登台添笑料  时髦抢眼挺风流  [1, 0, 1, 0, 1, 1, 0]  [1, 0, 1, 0, 1, 1, 0]   \n",
       "159998      1  雨打芳林花溅泪  风吹古柏树参天  [1, 1, 1, 0, 0, 1, 0]  [1, 1, 1, 0, 0, 1, 0]   \n",
       "159999      0  兰草絮语堪留醉  花铺地毯秀娇容  [1, 0, 1, 0, 1, 1, 1]  [1, 0, 1, 0, 1, 1, 0]   \n",
       "\n",
       "                          POS1                    POS2  \n",
       "0        [11, 11, 7, 11, 7, 7]    [7, 15, 15, 7, 2, 2]  \n",
       "1         [7, 7, 0, 0, 15, 11]     [7, 7, 0, 0, 15, 0]  \n",
       "2         [15, 7, 7, 7, 15, 7]   [15, 0, 7, 7, 15, 11]  \n",
       "3         [15, 15, 7, 7, 7, 7]  [11, 15, 7, 7, 11, 11]  \n",
       "4         [8, 7, 7, 7, 11, 11]    [8, 7, 7, 7, 15, 15]  \n",
       "...                        ...                     ...  \n",
       "159995      [7, 7, 7, 7, 2, 0]     [7, 7, 7, 7, 2, 15]  \n",
       "159996  [3, 3, 15, 15, 15, 15]  [11, 11, 9, 7, 15, 11]  \n",
       "159997   [7, 7, 15, 15, 15, 7]      [0, 0, 0, 0, 2, 0]  \n",
       "159998   [15, 15, 7, 7, 7, 15]    [7, 15, 7, 7, 7, 15]  \n",
       "159999    [7, 7, 7, 7, 15, 15]    [7, 15, 7, 7, 15, 0]  \n",
       "\n",
       "[160000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>word_seg1</th>\n",
       "      <th>word_seg2</th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>个个爱弹廉政曲</td>\n",
       "      <td>昂首挺胸不求人</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 1]</td>\n",
       "      <td>[7, 7, 3, 15, 7, 7]</td>\n",
       "      <td>[15, 15, 15, 15, 2, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>春堤榆柳烟笼翠</td>\n",
       "      <td>夏苑牡丹影泛红</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[7, 7, 7, 7, 7, 15]</td>\n",
       "      <td>[11, 11, 7, 7, 7, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>三溪水笑联花艳</td>\n",
       "      <td>双凤山清诗意浓</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 1]</td>\n",
       "      <td>[11, 11, 9, 15, 15, 7]</td>\n",
       "      <td>[11, 11, 9, 0, 7, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>竹篙桂楫飞如箭</td>\n",
       "      <td>鹤性松心合在山</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[7, 7, 7, 7, 15, 15]</td>\n",
       "      <td>[11, 11, 11, 11, 15, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>风添红袖三分瘦</td>\n",
       "      <td>梦枕秋肩一晚凉</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1]</td>\n",
       "      <td>[7, 15, 7, 7, 8, 7]</td>\n",
       "      <td>[15, 15, 7, 7, 8, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>0</td>\n",
       "      <td>扭扭捏捏当公主</td>\n",
       "      <td>远景熙和岛上香</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 0]</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 2, 15, 7]</td>\n",
       "      <td>[11, 11, 11, 11, 7, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>0</td>\n",
       "      <td>千山景色常入眼</td>\n",
       "      <td>光明心事月当天</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 0]</td>\n",
       "      <td>[8, 7, 7, 7, 2, 15]</td>\n",
       "      <td>[11, 11, 7, 7, 9, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1</td>\n",
       "      <td>一溪弹破空山寂</td>\n",
       "      <td>几树妆成野岭春</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[11, 11, 15, 15, 7, 7]</td>\n",
       "      <td>[8, 7, 15, 15, 11, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>0</td>\n",
       "      <td>苍凉是酒别开口</td>\n",
       "      <td>月色酬君满腹诗</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 0]</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 1]</td>\n",
       "      <td>[7, 7, 3, 7, 2, 15]</td>\n",
       "      <td>[7, 7, 15, 15, 15, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>0</td>\n",
       "      <td>梦里春风多少曲</td>\n",
       "      <td>红楼绿树万家春</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[7, 7, 7, 7, 8, 8]</td>\n",
       "      <td>[11, 11, 7, 7, 8, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label    text1    text2              word_seg1              word_seg2  \\\n",
       "0          0  个个爱弹廉政曲  昂首挺胸不求人  [1, 0, 1, 1, 1, 0, 0]  [1, 0, 0, 0, 1, 1, 1]   \n",
       "1          1  春堤榆柳烟笼翠  夏苑牡丹影泛红  [1, 1, 1, 1, 1, 0, 1]  [1, 0, 1, 0, 1, 1, 0]   \n",
       "2          1  三溪水笑联花艳  双凤山清诗意浓  [1, 0, 1, 1, 1, 1, 1]  [1, 0, 0, 1, 1, 0, 1]   \n",
       "3          1  竹篙桂楫飞如箭  鹤性松心合在山  [1, 0, 1, 1, 1, 1, 1]  [1, 0, 1, 1, 1, 1, 1]   \n",
       "4          1  风添红袖三分瘦  梦枕秋肩一晚凉  [1, 1, 1, 0, 1, 1, 1]  [1, 1, 1, 0, 1, 1, 1]   \n",
       "...      ...      ...      ...                    ...                    ...   \n",
       "39995      0  扭扭捏捏当公主  远景熙和岛上香  [1, 0, 0, 0, 1, 1, 0]  [1, 0, 1, 0, 0, 1, 1]   \n",
       "39996      0  千山景色常入眼  光明心事月当天  [1, 1, 1, 0, 1, 1, 0]  [1, 0, 1, 0, 1, 1, 0]   \n",
       "39997      1  一溪弹破空山寂  几树妆成野岭春  [1, 1, 1, 1, 1, 1, 1]  [1, 1, 1, 1, 1, 1, 1]   \n",
       "39998      0  苍凉是酒别开口  月色酬君满腹诗  [1, 0, 1, 1, 1, 1, 0]  [1, 0, 1, 1, 1, 0, 1]   \n",
       "39999      0  梦里春风多少曲  红楼绿树万家春  [1, 1, 1, 0, 1, 0, 1]  [1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                         POS1                      POS2  \n",
       "0         [7, 7, 3, 15, 7, 7]   [15, 15, 15, 15, 2, 15]  \n",
       "1         [7, 7, 7, 7, 7, 15]     [11, 11, 7, 7, 7, 15]  \n",
       "2      [11, 11, 9, 15, 15, 7]      [11, 11, 9, 0, 7, 7]  \n",
       "3        [7, 7, 7, 7, 15, 15]  [11, 11, 11, 11, 15, 15]  \n",
       "4         [7, 15, 7, 7, 8, 7]      [15, 15, 7, 7, 8, 7]  \n",
       "...                       ...                       ...  \n",
       "39995     [0, 0, 0, 2, 15, 7]    [11, 11, 11, 11, 7, 7]  \n",
       "39996     [8, 7, 7, 7, 2, 15]      [11, 11, 7, 7, 9, 7]  \n",
       "39997  [11, 11, 15, 15, 7, 7]    [8, 7, 15, 15, 11, 11]  \n",
       "39998     [7, 7, 3, 7, 2, 15]    [7, 7, 15, 15, 15, 15]  \n",
       "39999      [7, 7, 7, 7, 8, 8]      [11, 11, 7, 7, 8, 7]  \n",
       "\n",
       "[40000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import data for SNN training and testing\n",
    "\n",
    "snn_data = pd.read_csv('couplets_snn_v2.csv').iloc[:, 1:]\n",
    "\n",
    "np.random.seed(6)\n",
    "shuffled_index_data = np.random.permutation(snn_data.index)\n",
    "data_shuffled = snn_data.iloc[shuffled_index_data]\n",
    "train, test = train_test_split(data_shuffled, test_size=0.2, random_state=6, stratify=data_shuffled['label'])\n",
    "# train.to_csv('couplets_snn.csv', index=False)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "display(train)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the class for dataloader\n",
    "class CoupletsDataSNN(Dataset):\n",
    "    def __init__(self, data, max_len, tokenizer):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.data.iloc[index, 0]\n",
    "        text = \"\".join(self.data.iloc[index, 1:3])\n",
    "\n",
    "        word_seg1 = torch.tensor(ast.literal_eval(self.data.iloc[index, 3]))\n",
    "        word_seg2 = torch.tensor(ast.literal_eval(self.data.iloc[index, 4]))\n",
    "        pos1 = torch.tensor(ast.literal_eval(self.data.iloc[index, 5]))\n",
    "        pos2 = torch.tensor(ast.literal_eval(self.data.iloc[index, 6]))\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text, \n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        input1 = torch.concat([input_ids[:(self.max_len) // 2].float(), word_seg1.float(), pos1.float()])\n",
    "        input2 = torch.concat([input_ids[(self.max_len) // 2:].float(), word_seg2.float(), pos2.float()])\n",
    "\n",
    "        return input1, input2, label\n",
    "\n",
    "# Define the shared subnetwork\n",
    "class SharedSubnetwork(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=120, output_dim=10):\n",
    "        super(SharedSubnetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 4, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "# Define the Siamese Neural Network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.shared_network = SharedSubnetwork()\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        # Pass both inputs through the shared subnetwork\n",
    "        output1 = self.shared_network(input1)\n",
    "        output2 = self.shared_network(input2)\n",
    "        # Compute the cosine similarity\n",
    "        similarity = F.cosine_similarity(output1, output2, dim=1)\n",
    "        # print(f\"distance: {distance}\")\n",
    "        return similarity\n",
    "\n",
    "# Define the contrastive loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, similarity, label):\n",
    "        # Convert similarity to distance for loss computation\n",
    "        loss = (1 - label) * torch.pow(similarity, 2) + \\\n",
    "               label * torch.pow(torch.clamp(self.margin - similarity, min=0.0), 2)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_siamese_network(model, dataloader, optimizer, loss_fn, epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for input1, input2, label in dataloader:\n",
    "            input1, input2, label = input1.to(device), input2.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            similarity = model(input1, input2)\n",
    "            loss = loss_fn(similarity, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0676\n",
      "Epoch [2/20], Loss: 0.0625\n",
      "Epoch [3/20], Loss: 0.0621\n",
      "Epoch [4/20], Loss: 0.0618\n",
      "Epoch [5/20], Loss: 0.0616\n",
      "Epoch [6/20], Loss: 0.0615\n",
      "Epoch [7/20], Loss: 0.0613\n",
      "Epoch [8/20], Loss: 0.0612\n",
      "Epoch [9/20], Loss: 0.0612\n",
      "Epoch [10/20], Loss: 0.0610\n",
      "Epoch [11/20], Loss: 0.0609\n",
      "Epoch [12/20], Loss: 0.0610\n",
      "Epoch [13/20], Loss: 0.0608\n",
      "Epoch [14/20], Loss: 0.0608\n",
      "Epoch [15/20], Loss: 0.0607\n",
      "Epoch [16/20], Loss: 0.0607\n",
      "Epoch [17/20], Loss: 0.0606\n",
      "Epoch [18/20], Loss: 0.0606\n",
      "Epoch [19/20], Loss: 0.0606\n",
      "Epoch [20/20], Loss: 0.0606\n",
      "Entire model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training start\n",
    "if __name__ == \"__main__\":\n",
    "    dataloader = DataLoader(CoupletsDataSNN(train, 14, tokenizer), batch_size=128, shuffle=True)\n",
    "    \n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = SiameseNetwork().to(device)\n",
    "    loss_fn = ContrastiveLoss(margin=0.5)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train the model\n",
    "    train_siamese_network(model, dataloader, optimizer, loss_fn, epochs=20)\n",
    "\n",
    "    torch.save(model, \"siamese_model_complete.pth\")\n",
    "    print(\"Entire model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test = test.drop(columns=['label'])\n",
    "class TestDataSNN(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=14):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = \"\".join(self.data.iloc[index, 0:2])\n",
    "        word_seg1 = torch.tensor(ast.literal_eval(self.data.iloc[index, 2]))\n",
    "        word_seg2 = torch.tensor(ast.literal_eval(self.data.iloc[index, 3]))\n",
    "        pos1 = torch.tensor(ast.literal_eval(self.data.iloc[index, 4]))\n",
    "        pos2 = torch.tensor(ast.literal_eval(self.data.iloc[index, 5]))\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text, \n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        input1 = torch.concat([input_ids[:(self.max_len) // 2].float(), word_seg1.float(), pos1.float()])\n",
    "        input2 = torch.concat([input_ids[(self.max_len) // 2:].float(), word_seg2.float(), pos2.float()])\n",
    "        return input1, input2\n",
    "\n",
    "# dataloader = DataLoader(TestDataSNN(test.iloc[:,1:], tokenizer), batch_size=1, shuffle=True)\n",
    "# for input1, input2 in dataloader:\n",
    "#     input1, input2 = input1.to(device), input2.to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         similarity = model(input1, input2)\n",
    "#         print(similarity.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(model, val_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input1, input2, labels in val_loader:\n",
    "            input1, input2, labels = input1.to(device), input2.to(device), labels.to(device)\n",
    "            scores = model(input1, input2)  # Cosine similarity\n",
    "            all_scores.extend(scores.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
    "    optimal_idx = (tpr - fpr).argmax()\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "    return optimal_threshold\n",
    "\n",
    "def test_snn_model(model, test_data, max_len, tokenizer, batch_size=32, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Test the trained Siamese Neural Network model on test data.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained SNN model.\n",
    "        test_data (pd.DataFrame): Test dataset as a DataFrame.\n",
    "        max_len (int): Maximum sequence length for tokenization.\n",
    "        tokenizer: Tokenizer to preprocess the text.\n",
    "        batch_size (int): Batch size for testing.\n",
    "        threshold (float): Threshold to classify similarity.\n",
    "    \n",
    "    Returns:\n",
    "        None: Prints test metrics (accuracy, precision, recall, F1-score).\n",
    "    \"\"\"\n",
    "    # Prepare the test dataset and dataloader\n",
    "    test_dataset = CoupletsDataSNN(test_data, max_len, tokenizer)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input1, input2, labels in test_loader:\n",
    "            # Move data to the appropriate device\n",
    "            input1, input2, labels = input1.to(device), input2.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            similarity_scores = model(input1, input2)  # Cosine similarity values\n",
    "            \n",
    "            # Convert similarity scores to binary predictions\n",
    "            predictions = (similarity_scores >= threshold).float()\n",
    "            \n",
    "            # Store labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=1)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=1)\n",
    "    f1 = f1_score(all_labels, all_predictions, zero_division=1)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.2538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2538063"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_dataset = CoupletsDataSNN(test, 14, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "threshold = find_optimal_threshold(model, test_loader)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5680\n",
      "Test Precision: 0.5753\n",
      "Test Recall: 0.5191\n",
      "Test F1-Score: 0.5458\n"
     ]
    }
   ],
   "source": [
    "test_snn_model(model, test, 14, tokenizer, batch_size=32, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
