{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76c40bf-2613-4cbf-a735-0358d698fe14",
   "metadata": {},
   "source": [
    "# 1. Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbff8584-eda4-4d00-84b9-43cc00256f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# Regular Expression (RegEx），to search, match and encode Chinese character\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "import ltp\n",
    "from ltp import LTP\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54493d4-1d28-4598-9c55-b4b03df9627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "329c59c2-446b-44d2-aae1-09ec01e148ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.13\n"
     ]
    }
   ],
   "source": [
    "print(ltp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "600c93ee-3be5-4df1-bd6d-d234020b53ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/ltp/nerual.py:552: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_file, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "ltp = LTP()  # load the default model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec331e22-7d19-4637-879b-26d30a1889c7",
   "metadata": {},
   "source": [
    "## 1.1. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf76841-36b4-4347-a178-e22df7b0e4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Result: [['清华大学', '是', '一', '所', '著名', '的', '高等', '学府', '。']]\n"
     ]
    }
   ],
   "source": [
    "result = ltp.pipeline([\"清华大学是一所著名的高等学府。\"], tasks=[\"cws\"])\n",
    "print(\"Segmentation Result:\", result.cws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e9b1b4-4883-4a55-81e9-10facddb52ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result.cws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7cc5f48-9abf-45ae-9b6a-5c0a02713661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation: ['清华大学', '是', '一', '所', '著名', '的', '高等', '学府', '。']\n",
      "Lexical Annotation: ['ni', 'v', 'm', 'q', 'a', 'u', 'b', 'n', 'wp']\n",
      "Verb list: ['是']\n"
     ]
    }
   ],
   "source": [
    "# input the sentence\n",
    "sentence = [\"清华大学是一所著名的高等学府。\"]\n",
    "\n",
    "# Segmentation and lexical annotation by pipeline\n",
    "result = ltp.pipeline(sentence, tasks=[\"cws\", \"pos\"])\n",
    "\n",
    "# Segmentation results\n",
    "seg = result.cws[0]\n",
    "print(\"Segmentation:\", seg)\n",
    "\n",
    "# Lexical annotation results\n",
    "pos = result.pos[0]\n",
    "print(\"Lexical Annotation:\", pos)\n",
    "\n",
    "# Extracting verbs (LTP uses 'v' for verbs)\n",
    "verbs = [word for word, tag in zip(seg, pos) if tag == \"v\"]\n",
    "print(\"Verb list:\", verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723eea9-cb4a-401e-860e-d033544c72bc",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80856bb-cd11-40d1-a9a9-5f8db3ea78e4",
   "metadata": {},
   "source": [
    "## 2.1. Former Couplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98392a31-0214-4f15-bd6b-7a6f1282f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"in上联.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    former = [line.strip() for line in file if line.strip()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fdfe938-4829-44f3-9fc7-1fee0b3e58b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741096"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(former)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f2520-c604-4bc0-bacd-342b4564e50e",
   "metadata": {},
   "source": [
    "## 2.2. Later Couplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af6b7d6d-bbba-43f7-bc34-d032050a90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out下联.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    later = [line.strip() for line in file if line.strip()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7055a42-5e7f-431f-a016-7c38ae2a7f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741096"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953d27a-0119-4ff9-bdc0-eacfeacfa0f6",
   "metadata": {},
   "source": [
    "## 2.3. Couplet Merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dd0b2f7-da6a-4555-8bac-fff639b71e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet = pd.DataFrame({'Column1': former, 'Column2': later})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4fdb393-fb0c-48d9-9f18-fc17e401aa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>晚 风 摇 树 树 还 挺</td>\n",
       "      <td>晨 露 润 花 花 更 红</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>愿 景 天 成 无 墨 迹</td>\n",
       "      <td>万 方 乐 奏 有 于 阗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>丹 枫 江 冷 人 初 去</td>\n",
       "      <td>绿 柳 堤 新 燕 复 来</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>忽 忽 几 晨 昏 ， 离 别 间 之 ， 疾 病 间 之 ， 不 及 终 年 同 静 好</td>\n",
       "      <td>茕 茕 小 儿 女 ， 孱 羸 若 此 ， 娇 憨 若 此 ， 更 烦 二 老 费 精 神</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>闲 来 野 钓 人 稀 处</td>\n",
       "      <td>兴 起 高 歌 酒 醉 中</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741091</th>\n",
       "      <td>半 榻 诗 书 盈 陋 室</td>\n",
       "      <td>一 墙 字 画 靓 寒 庐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741092</th>\n",
       "      <td>借 角 青 山 埋 姓 字</td>\n",
       "      <td>掬 壶 明 月 洗 尘 心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741093</th>\n",
       "      <td>苑 内 尽 天 姿 ， 锦 窠 仙 髻 无 双 艳</td>\n",
       "      <td>亭 前 多 国 色 ， 金 粉 紫 檀 第 一 香</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741094</th>\n",
       "      <td>浩 淼 洞 庭 ， 极 目 天 为 界</td>\n",
       "      <td>安 闲 钓 叟 ， 静 心 孰 羡 鱼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741095</th>\n",
       "      <td>志 踏 云 梯 能 揽 月</td>\n",
       "      <td>坚 磨 铁 棒 可 成 针</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741096 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Column1  \\\n",
       "0                                       晚 风 摇 树 树 还 挺   \n",
       "1                                       愿 景 天 成 无 墨 迹   \n",
       "2                                       丹 枫 江 冷 人 初 去   \n",
       "3       忽 忽 几 晨 昏 ， 离 别 间 之 ， 疾 病 间 之 ， 不 及 终 年 同 静 好   \n",
       "4                                       闲 来 野 钓 人 稀 处   \n",
       "...                                               ...   \n",
       "741091                                  半 榻 诗 书 盈 陋 室   \n",
       "741092                                  借 角 青 山 埋 姓 字   \n",
       "741093                      苑 内 尽 天 姿 ， 锦 窠 仙 髻 无 双 艳   \n",
       "741094                            浩 淼 洞 庭 ， 极 目 天 为 界   \n",
       "741095                                  志 踏 云 梯 能 揽 月   \n",
       "\n",
       "                                              Column2  \n",
       "0                                       晨 露 润 花 花 更 红  \n",
       "1                                       万 方 乐 奏 有 于 阗  \n",
       "2                                       绿 柳 堤 新 燕 复 来  \n",
       "3       茕 茕 小 儿 女 ， 孱 羸 若 此 ， 娇 憨 若 此 ， 更 烦 二 老 费 精 神  \n",
       "4                                       兴 起 高 歌 酒 醉 中  \n",
       "...                                               ...  \n",
       "741091                                  一 墙 字 画 靓 寒 庐  \n",
       "741092                                  掬 壶 明 月 洗 尘 心  \n",
       "741093                      亭 前 多 国 色 ， 金 粉 紫 檀 第 一 香  \n",
       "741094                            安 闲 钓 叟 ， 静 心 孰 羡 鱼  \n",
       "741095                                  坚 磨 铁 棒 可 成 针  \n",
       "\n",
       "[741096 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "couplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3eeb0ef4-3c35-4003-b764-48f709ef2bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(couplet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2f97e-b2f0-4dc6-8c74-27ec05bf211d",
   "metadata": {},
   "source": [
    "# 3. Data Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bf960-e489-4599-bed6-ff35af65f52e",
   "metadata": {},
   "source": [
    "## 3.1. Remove non-Chinese characters from each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ecb0394-3c13-4d39-8774-efdd2e1c9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_only_chinese(s):\n",
    "    # Extract all Chinese characters using regular expressions\n",
    "    chinese_characters = re.findall(r'[\\u4e00-\\u9fff]', s)\n",
    "    # Re-splicing the extracted Chinese characters into a string\n",
    "    return ''.join(chinese_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "348f8dac-01ed-463b-8d6d-65eaa65d9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_former_1 = [keep_only_chinese(line) for line in former]\n",
    "cleaned_later_1 = [keep_only_chinese(line) for line in later]\n",
    "\n",
    "# Apply the function to each column of the DataFrame\n",
    "cleaned_couplet_1 = couplet\n",
    "cleaned_couplet_1['Column1'] = cleaned_couplet_1['Column1'].apply(keep_only_chinese)\n",
    "cleaned_couplet_1['Column2'] = cleaned_couplet_1['Column2'].apply(keep_only_chinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59e81681-f2f4-4365-b08e-b913e7b19201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of cleaned_former_1 is 741096\n",
      "The length of cleaned_later_1 is 741096\n",
      "cleaned_couplet_1(df）has 741096 rows\n"
     ]
    }
   ],
   "source": [
    "print('The length of cleaned_former_1 is',len(cleaned_former_1))\n",
    "print('The length of cleaned_later_1 is',len(cleaned_later_1))\n",
    "print('cleaned_couplet_1(df）has',cleaned_couplet_1.shape[0],'rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7d0f4f1-2558-48a4-9d78-d3008666bd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>晚风摇树树还挺</td>\n",
       "      <td>晨露润花花更红</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>愿景天成无墨迹</td>\n",
       "      <td>万方乐奏有于阗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>丹枫江冷人初去</td>\n",
       "      <td>绿柳堤新燕复来</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>忽忽几晨昏离别间之疾病间之不及终年同静好</td>\n",
       "      <td>茕茕小儿女孱羸若此娇憨若此更烦二老费精神</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>闲来野钓人稀处</td>\n",
       "      <td>兴起高歌酒醉中</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741091</th>\n",
       "      <td>半榻诗书盈陋室</td>\n",
       "      <td>一墙字画靓寒庐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741092</th>\n",
       "      <td>借角青山埋姓字</td>\n",
       "      <td>掬壶明月洗尘心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741093</th>\n",
       "      <td>苑内尽天姿锦窠仙髻无双艳</td>\n",
       "      <td>亭前多国色金粉紫檀第一香</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741094</th>\n",
       "      <td>浩淼洞庭极目天为界</td>\n",
       "      <td>安闲钓叟静心孰羡鱼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741095</th>\n",
       "      <td>志踏云梯能揽月</td>\n",
       "      <td>坚磨铁棒可成针</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741096 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Column1               Column2\n",
       "0                    晚风摇树树还挺               晨露润花花更红\n",
       "1                    愿景天成无墨迹               万方乐奏有于阗\n",
       "2                    丹枫江冷人初去               绿柳堤新燕复来\n",
       "3       忽忽几晨昏离别间之疾病间之不及终年同静好  茕茕小儿女孱羸若此娇憨若此更烦二老费精神\n",
       "4                    闲来野钓人稀处               兴起高歌酒醉中\n",
       "...                      ...                   ...\n",
       "741091               半榻诗书盈陋室               一墙字画靓寒庐\n",
       "741092               借角青山埋姓字               掬壶明月洗尘心\n",
       "741093          苑内尽天姿锦窠仙髻无双艳          亭前多国色金粉紫檀第一香\n",
       "741094             浩淼洞庭极目天为界             安闲钓叟静心孰羡鱼\n",
       "741095               志踏云梯能揽月               坚磨铁棒可成针\n",
       "\n",
       "[741096 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_couplet_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21816d33-d4f5-4433-a5ad-a9ec6b03331e",
   "metadata": {},
   "source": [
    "## 3.2. Retain only the rows where the number of Chinese characters is 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c77cfb67-654c-4398-91b2-262255af2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'^[\\u4e00-\\u9fff]{7}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f5572bf-2632-474a-a762-c1184cab7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_former_2 = [sentence for sentence in cleaned_former_1 if pattern.match(sentence)]\n",
    "cleaned_later_2 = [sentence for sentence in cleaned_later_1 if pattern.match(sentence)]\n",
    "\n",
    "# 同时检查 Column1 和 Column2\n",
    "cleaned_couplet_2 = cleaned_couplet_1[\n",
    "    cleaned_couplet_1['Column1'].apply(lambda x: bool(pattern.match(x))) &\n",
    "    cleaned_couplet_1['Column2'].apply(lambda x: bool(pattern.match(x)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf836244-1d11-427d-bcc7-2cf847d9c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of cleaned_former_2 is 346104\n",
      "The length of cleaned_later_2 is 346104\n",
      "cleaned_couplet_2(df）has 346097 rows\n"
     ]
    }
   ],
   "source": [
    "print('The length of cleaned_former_2 is',len(cleaned_former_2))\n",
    "print('The length of cleaned_later_2 is',len(cleaned_later_2))\n",
    "print('cleaned_couplet_2(df）has',cleaned_couplet_2.shape[0],'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a53f3087-e934-41c6-8622-44fcfb80a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of eligible rows for Column1: 346104\n",
      "The number of eligible rows for Column2: 346104\n"
     ]
    }
   ],
   "source": [
    "# Check the number of eligible rows for Column1\n",
    "column1_valid = cleaned_couplet_1['Column1'].apply(lambda x: bool(pattern.match(x))).sum()\n",
    "print(f\"The number of eligible rows for Column1: {column1_valid}\")\n",
    "\n",
    "# Check the number of eligible rows for Column2\n",
    "column2_valid = cleaned_couplet_1['Column2'].apply(lambda x: bool(pattern.match(x))).sum()\n",
    "print(f\"The number of eligible rows for Column2: {column2_valid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7bae6257-e111-4cc2-95eb-78f32ac67055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the merged data is: 346104\n"
     ]
    }
   ],
   "source": [
    "valid_couplet_df = pd.DataFrame({\n",
    "    'Column1': cleaned_couplet_1['Column1'][cleaned_couplet_1['Column1'].apply(lambda x: bool(pattern.match(x)))].tolist(),\n",
    "    'Column2': cleaned_couplet_1['Column2'][cleaned_couplet_1['Column2'].apply(lambda x: bool(pattern.match(x)))].tolist()\n",
    "})\n",
    "\n",
    "print(f\"The length of the merged data is: {len(valid_couplet_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8dc2ad98-6e8b-434a-b4bb-47cb883212f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column1  Column2\n",
      "0       晚风摇树树还挺  晨露润花花更红\n",
      "1       愿景天成无墨迹  万方乐奏有于阗\n",
      "2       丹枫江冷人初去  绿柳堤新燕复来\n",
      "3       闲来野钓人稀处  兴起高歌酒醉中\n",
      "4       投石向天跟命斗  闭门问卷与时争\n",
      "...         ...      ...\n",
      "346099  寺镇摩尼青色宝  山飞舍利紫祥光\n",
      "346100  呼饭为斋禅十足  借鸡生蛋利三分\n",
      "346101  半榻诗书盈陋室  一墙字画靓寒庐\n",
      "346102  借角青山埋姓字  掬壶明月洗尘心\n",
      "346103  志踏云梯能揽月  坚磨铁棒可成针\n",
      "\n",
      "[346104 rows x 2 columns]\n",
      "        Column1  Column2\n",
      "0       晚风摇树树还挺  晨露润花花更红\n",
      "1       愿景天成无墨迹  万方乐奏有于阗\n",
      "2       丹枫江冷人初去  绿柳堤新燕复来\n",
      "4       闲来野钓人稀处  兴起高歌酒醉中\n",
      "6       投石向天跟命斗  闭门问卷与时争\n",
      "...         ...      ...\n",
      "741087  寺镇摩尼青色宝  山飞舍利紫祥光\n",
      "741089  呼饭为斋禅十足  借鸡生蛋利三分\n",
      "741091  半榻诗书盈陋室  一墙字画靓寒庐\n",
      "741092  借角青山埋姓字  掬壶明月洗尘心\n",
      "741095  志踏云梯能揽月  坚磨铁棒可成针\n",
      "\n",
      "[346097 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(valid_couplet_df)\n",
    "print(cleaned_couplet_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5e3d614-277f-4ef6-a164-ce4246f50c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing rows: 219422\n",
      "        Column1  Column2\n",
      "12535   静夜残风添寂寞  才雄能应人际情\n",
      "12536   性懒全抛世俗事  水月调弦淡雅风\n",
      "12537   山泉出句清廉韵  红枫霜重雁乌寒\n",
      "12538   碧海潮生鱼龙跃  背后常多算计人\n",
      "12539   尘中哪有笔直路  文近天然雅自生\n",
      "...         ...      ...\n",
      "330760  抱手围棋观胜负  绿水青山室外琴\n",
      "330761  红云碧宇天然画  九州织梦绣图新\n",
      "330762  百会征联文集雅  虎大了无狼狗欺\n",
      "330764  人穷时有蚊虫咬  一轮蟾影恰当帘\n",
      "330765  四面岚光俱入座  有时云峤听钩辀\n",
      "\n",
      "[219422 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the difference set with `pd.merge`.\n",
    "missing_rows = valid_couplet_df.merge(cleaned_couplet_2, on=['Column1', 'Column2'], how='left', indicator=True)\n",
    "missing_rows = missing_rows[missing_rows['_merge'] == 'left_only']\n",
    "\n",
    "print(f\"Number of missing rows: {len(missing_rows)}\")\n",
    "print(missing_rows[['Column1', 'Column2']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44b734-5d61-41f5-92cb-3d7c92e360e5",
   "metadata": {},
   "source": [
    "## 3.3. Reset Row Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2301e49-0fcd-4297-88ab-b6c56bd9a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Row Index\n",
    "cleaned_couplet_3 = cleaned_couplet_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2185c604-3a08-4aae-be16-a38b00429f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column1  Column2\n",
      "0       晚风摇树树还挺  晨露润花花更红\n",
      "1       愿景天成无墨迹  万方乐奏有于阗\n",
      "2       丹枫江冷人初去  绿柳堤新燕复来\n",
      "3       闲来野钓人稀处  兴起高歌酒醉中\n",
      "4       投石向天跟命斗  闭门问卷与时争\n",
      "...         ...      ...\n",
      "346092  寺镇摩尼青色宝  山飞舍利紫祥光\n",
      "346093  呼饭为斋禅十足  借鸡生蛋利三分\n",
      "346094  半榻诗书盈陋室  一墙字画靓寒庐\n",
      "346095  借角青山埋姓字  掬壶明月洗尘心\n",
      "346096  志踏云梯能揽月  坚磨铁棒可成针\n",
      "\n",
      "[346097 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_couplet_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e6260-e124-4d17-a820-f9dc5997c211",
   "metadata": {},
   "source": [
    "## 3.4. Remove duplicate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4611649-eba5-4c9d-aefb-8e0c4611c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate rows and get their location and number of repetitions\n",
    "def find_duplicates(df):\n",
    "    # Find all duplicate rows\n",
    "    duplicates = df[df.duplicated(keep=False)]\n",
    "    \n",
    "    # Count the number of repetitions per line\n",
    "    duplicate_counts = df.duplicated(keep=False).value_counts()\n",
    "    \n",
    "    # Getting the index of duplicate rows\n",
    "    duplicate_indices = duplicates.index.tolist()\n",
    "    \n",
    "    # Print information of duplicate lines\n",
    "    print(\"Information of duplicate lines:\")\n",
    "    for index in duplicate_indices:\n",
    "        # Find identical rows\n",
    "        duplicate_rows = df[df.apply(lambda row: row.equals(df.loc[index]), axis=1)]\n",
    "        \n",
    "        print(f\"\\n The information of thw duplicate line {index}\")\n",
    "        print(duplicate_rows)\n",
    "        print(f\"This row duplicated {len(duplicate_rows)} times\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Return the total number of duplicate rows and details\n",
    "    return {\n",
    "        'total_duplicates': len(duplicates),\n",
    "        'duplicate_indices': duplicate_indices\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9ece31c-1f9d-415c-8ed0-642c4c7ba3c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "#####\n",
    "#WARNING!!! DO NOT RUN!!! TIME CONSUMER!!!\n",
    "#####\n",
    "#####\n",
    "\n",
    "# duplicate_info = find_duplicates(cleaned_couplet_3)\n",
    "# print(\"\\n The number of duplicates :\", duplicate_info['total_duplicates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "deaf0b05-da85-4401-94a2-aeb06498420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of duplicate lines: 2296\n",
      "\n",
      " Number of occurrences of the repeated rows:\n",
      "Column1  Column2\n",
      "一世尘缘难舍弃  三生爱恋不归来    2\n",
      "一丝惆怅无端起  几许苍凉暗上来    2\n",
      "一代名师人逝去  千秋华表鹤飞来    2\n",
      "一任岁月随风去  不辞春光带雨来    2\n",
      "一别挥手从军去  几度焚林放火来    2\n",
      "                   ..\n",
      "龙腾华夏宏图起  燕舞新春福气来    2\n",
      "龙腾沧海卷雪去  虎踞灵山迎春来    2\n",
      "龙腾虎跃忍疼去  猴年马月终会来    2\n",
      "龙蟠沧海贺岁去  虎踞灵山迎春来    2\n",
      "龙门有兆春风起  泉眼无声活水来    2\n",
      "Length: 1148, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group counting by identical rows\n",
    "duplicate_counts = cleaned_couplet_3.duplicated(keep=False)\n",
    "detail_duplicates = cleaned_couplet_3[duplicate_counts]\n",
    "\n",
    "# Print the number of duplicate lines\n",
    "print(\"Total number of duplicate lines:\", len(detail_duplicates))\n",
    "\n",
    "# Print the number of times each repeating line occurs\n",
    "print(\"\\n Number of occurrences of the repeated rows:\")\n",
    "print(detail_duplicates.groupby(detail_duplicates.columns.tolist()).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be23d366-6eca-49f4-8d9d-77d4c0c7035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows and keep the first occurrence\n",
    "cleaned_couplet_4 = cleaned_couplet_3.drop_duplicates()\n",
    "\n",
    "# Reset indexes\n",
    "cleaned_couplet_4 = cleaned_couplet_4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47ee7305-3b6c-4874-88c1-ce9d6702a973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_couplet_4(df) has  344949 rows\n"
     ]
    }
   ],
   "source": [
    "print('cleaned_couplet_4(df) has ',cleaned_couplet_4.shape[0],'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75cfade7-aa87-4c83-ab38-8fcb1823ddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column1  Column2\n",
      "0       晚风摇树树还挺  晨露润花花更红\n",
      "1       愿景天成无墨迹  万方乐奏有于阗\n",
      "2       丹枫江冷人初去  绿柳堤新燕复来\n",
      "3       闲来野钓人稀处  兴起高歌酒醉中\n",
      "4       投石向天跟命斗  闭门问卷与时争\n",
      "...         ...      ...\n",
      "344944  寺镇摩尼青色宝  山飞舍利紫祥光\n",
      "344945  呼饭为斋禅十足  借鸡生蛋利三分\n",
      "344946  半榻诗书盈陋室  一墙字画靓寒庐\n",
      "344947  借角青山埋姓字  掬壶明月洗尘心\n",
      "344948  志踏云梯能揽月  坚磨铁棒可成针\n",
      "\n",
      "[344949 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_couplet_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb328212-ecf4-402b-b0df-a8cdd9adae61",
   "metadata": {},
   "source": [
    "## 3.5. Further Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89baeffb-5aa1-4a5f-a108-47062f03c569",
   "metadata": {},
   "source": [
    "### 3.5.1. Whether all 7 Chinese characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e5b43fe-811c-41cb-b9ef-3d8054b8bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_chinese_characters(s):\n",
    "    # Use regular expressions to match all Chinese characters.\n",
    "    chinese_characters = re.findall(r'[\\u4e00-\\u9fff]', s)\n",
    "    # Returns the number of Chinese characters matched\n",
    "    return len(chinese_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70e24736-81a9-4c7e-859e-5d47b138d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the counter function\n",
    "chinese_count_df = pd.DataFrame({\n",
    "    'Column1_chinese_count': cleaned_couplet_4['Column1'].apply(count_chinese_characters),\n",
    "    'Column2_chinese_count': cleaned_couplet_4['Column2'].apply(count_chinese_characters)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "edf07357-cdfc-4e4b-9447-75e3f3c59b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two columns have all elements of 7 Chinese character: True\n"
     ]
    }
   ],
   "source": [
    "# Check both columns\n",
    "all_7_both_columns = all((chinese_count_df['Column1_chinese_count'] == 7) & \n",
    "                         (chinese_count_df['Column2_chinese_count'] == 7))\n",
    "print(\"The two columns have all elements of 7 Chinese character:\", all_7_both_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b85f1d-cf79-4674-a60e-af0ab5e37b52",
   "metadata": {},
   "source": [
    "### 3.5.2.  Determine whether a string contains non-Hanzi characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "83292827-9b49-42f7-848b-6ee70d0b5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_non_chinese_characters(s):\n",
    "    # Regular Expression Matching for Non-Chinese Characters\n",
    "    # [^\\u4e00-\\u9fff] matches all characters that are not Chinese characters\n",
    "    return bool(re.search(r'[^\\u4e00-\\u9fff]', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "845e1536-87db-4b40-8847-f90b141b4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_chinese_df = pd.DataFrame({\n",
    "    'Column1_has_non_chinese': cleaned_couplet_4['Column1'].apply(has_non_chinese_characters),\n",
    "    'Column2_has_non_chinese': cleaned_couplet_4['Column2'].apply(has_non_chinese_characters)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9eb35729-7af1-44b6-bc7c-33ebcd14d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Chinese character exists: False\n"
     ]
    }
   ],
   "source": [
    "non_chinese_both_columns = all((non_chinese_df['Column1_has_non_chinese'] == 7) & \n",
    "                               (non_chinese_df['Column2_has_non_chinese'] == 7))\n",
    "print(\"Non-Chinese character exists:\", non_chinese_both_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9bff66b4-d539-460c-9914-64ddcac0188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column1  Column2\n",
      "0       晚风摇树树还挺  晨露润花花更红\n",
      "1       愿景天成无墨迹  万方乐奏有于阗\n",
      "2       丹枫江冷人初去  绿柳堤新燕复来\n",
      "3       闲来野钓人稀处  兴起高歌酒醉中\n",
      "4       投石向天跟命斗  闭门问卷与时争\n",
      "...         ...      ...\n",
      "344944  寺镇摩尼青色宝  山飞舍利紫祥光\n",
      "344945  呼饭为斋禅十足  借鸡生蛋利三分\n",
      "344946  半榻诗书盈陋室  一墙字画靓寒庐\n",
      "344947  借角青山埋姓字  掬壶明月洗尘心\n",
      "344948  志踏云梯能揽月  坚磨铁棒可成针\n",
      "\n",
      "[344949 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_couplet_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb880f5-7513-4ac9-b467-b65833770be1",
   "metadata": {},
   "source": [
    "# 4. Mark Verb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf12fe3-9975-4585-a46f-5278ac6dc921",
   "metadata": {},
   "source": [
    "## 4.1. Package 'jieba' (dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1101e71-c04f-43ce-b54e-eecaf8e20a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义一个函数，用于标记动词为 1，其他词性为 0\n",
    "# def tag_verbs(sentence):\n",
    "#     # 使用 jieba 分词和词性标注\n",
    "#     words = pseg.cut(sentence)\n",
    "    \n",
    "#     # 结果列表，初始全为 0\n",
    "#     result = [0] * len(sentence)\n",
    "    \n",
    "#     # 遍历分词结果，根据词性标记\n",
    "#     for word, flag in words:\n",
    "#         if flag == 'v':  # 动词的词性标记为 'v'\n",
    "#             for i, char in enumerate(sentence):\n",
    "#                 if char in word:  # 如果字符属于当前词\n",
    "#                     result[i] = 1\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33c7e220-6424-4556-93a7-424a0290a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对上联和下联分别标记动词\n",
    "# cleaned_couplet_4['Column1_Tag'] = cleaned_couplet_4['Column1'].apply(tag_verbs)\n",
    "# cleaned_couplet_4['Column2_Tag'] = cleaned_couplet_4['Column2'].apply(tag_verbs)\n",
    "\n",
    "# # 查看结果\n",
    "# print(cleaned_couplet_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce060e-ecd5-4b65-822a-bba63cba4fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b9894-dd33-45f3-9acf-d1e74d34a52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9976d2-5fb7-44ee-8339-6f607237e609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96630e5a-6e6f-4fe4-baac-830029e25ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2c8118-91ac-42f3-8ab3-2ee3e54b2116",
   "metadata": {},
   "source": [
    "## 4.2. Package 'ltp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883cde25-cc1c-4bf0-a885-e68f12120466",
   "metadata": {},
   "source": [
    "### 4.2.1. Defining function for labeling verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4a0049c7-6ef9-48f0-82eb-52ba87d89914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/ltp/nerual.py:552: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_file, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "ltp = LTP()  # Loading the default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f726e8c6-8d3d-458e-837b-fee270205e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_verbs_by_character(sentence):\n",
    "    # Split sentences into individual characters\n",
    "    characters = list(sentence)\n",
    "    # Segmentation and lexical labeling of entire sentences using LTP\n",
    "    result = ltp.pipeline([sentence], tasks=[\"cws\", \"pos\"])\n",
    "    seg = result.cws[0]  # Segmentation result\n",
    "    pos = result.pos[0]  # Lexical annotation result\n",
    "\n",
    "    # Create verbatim lexical annotation result\n",
    "    tags = []\n",
    "    for char in characters:\n",
    "        # Check whether the current Chinese character appears in the segmentation result\n",
    "        if char in seg:\n",
    "            # If the kanji is found, get its lexical property\n",
    "            ## kanji ??? Chinese Character\n",
    "            index = seg.index(char)\n",
    "            tag = 1 if pos[index] == \"v\" else 0\n",
    "        else:\n",
    "            # If the kanji is not tagged by the LTP segmentation result, it defaults to a non-verb.\n",
    "            tag = 0\n",
    "        tags.append(tag)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b23c3ba7-5a25-4937-8e89-906a58665e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_verbs_by_character(\"志踏云梯能揽月\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b18bcef0-5365-4808-b553-1a7522d7a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Parallel Processing Functions\n",
    "def parallel_apply(func, data, num_processes=None):\n",
    "    \"\"\"\n",
    "    Function for parallel processing\n",
    "    - func: Function to be applied\n",
    "    - data: data set\n",
    "    - num_processes: Number of processes (default is number of CPU cores)\n",
    "    \"\"\"\n",
    "    if num_processes is None:\n",
    "        num_processes = cpu_count()  # Uses all CPU cores of the system\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(func, data)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8aac2b35-d745-45de-84f6-c679eb671038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing of two columns\n",
    "# cleaned_couplet_4['Column1_Verbs'] = parallel_apply(tag_verbs_by_character, cleaned_couplet_4['Column1'].tolist())\n",
    "# cleaned_couplet_4['Column2_Verbs'] = parallel_apply(tag_verbs_by_character, cleaned_couplet_4['Column2'].tolist())\n",
    "\n",
    "# print(cleaned_couplet_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7732b7-3b2f-467e-9e6c-8eb699366fc7",
   "metadata": {},
   "source": [
    "### 4.2.1. Small batch run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8d17f313-1e52-457c-aa23-edff1b0512aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet_0_10000 = cleaned_couplet_4.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "505335b5-be13-47be-b887-01142bc91bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet_10001_20000 = cleaned_couplet_4.iloc[10000:20000]  # Note that the index starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a077df89-95d9-4261-9048-bb0c8fbef138",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet_20001_30000 = cleaned_couplet_4.iloc[20000:30000]  # Note that the index starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e944230c-1978-4c35-83d9-85358a72fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet_30001_40000 = cleaned_couplet_4.iloc[30000:40000]  # Note that the index starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "696c6cc2-0c0b-482a-9692-096d1bd9033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Column1  Column2\n",
      "30000  镜里鬓霜为墨换  笔底文章因才活\n",
      "30001  黄莺紫燕迎春使  白雪红梅贺岁图\n",
      "30002  学士班联旧清秘  翰林风月小澄怀\n",
      "30003  桂馥须邀嘉客赏  桔黄应待国宾尝\n",
      "30004  花娇惹妒群蜂踩  果老夸张打马云\n",
      "...        ...      ...\n",
      "39995  寒泉漱月清秋味  白石游虾古色香\n",
      "39996  田家好客三沽酒  游子怀乡几弄弦\n",
      "39997  把盏纵横天下事  埋头旦暮主人心\n",
      "39998  超脱三界外难也  放浪五行中易乎\n",
      "39999  南山树绿弥清韵  古塔霞红溢雅情\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(couplet_30001_40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5f2c3fe-1834-4a93-af5a-1bcdf0caee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_3632\\1924295568.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  couplet_30001_40000['Column1_Tag'] = couplet_30001_40000['Column1'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Column1  Column2            Column1_Tag            Column2_Tag\n",
      "30000  镜里鬓霜为墨换  笔底文章因才活  [0, 0, 0, 0, 1, 0, 1]  [0, 0, 0, 0, 0, 0, 0]\n",
      "30001  黄莺紫燕迎春使  白雪红梅贺岁图  [0, 0, 0, 0, 0, 0, 1]  [0, 0, 0, 0, 0, 0, 0]\n",
      "30002  学士班联旧清秘  翰林风月小澄怀  [0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0]\n",
      "30003  桂馥须邀嘉客赏  桔黄应待国宾尝  [0, 0, 0, 1, 0, 0, 1]  [0, 0, 1, 1, 0, 0, 1]\n",
      "30004  花娇惹妒群蜂踩  果老夸张打马云  [0, 0, 1, 1, 0, 0, 1]  [0, 0, 0, 0, 0, 0, 0]\n",
      "...        ...      ...                    ...                    ...\n",
      "39995  寒泉漱月清秋味  白石游虾古色香  [0, 0, 1, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0]\n",
      "39996  田家好客三沽酒  游子怀乡几弄弦  [0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 1, 0]\n",
      "39997  把盏纵横天下事  埋头旦暮主人心  [0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0]\n",
      "39998  超脱三界外难也  放浪五行中易乎  [1, 1, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0]\n",
      "39999  南山树绿弥清韵  古塔霞红溢雅情  [0, 0, 0, 0, 1, 0, 0]  [0, 0, 0, 0, 1, 0, 0]\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_3632\\1924295568.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  couplet_30001_40000['Column2_Tag'] = couplet_30001_40000['Column2'].apply(tag_verbs_by_character)\n"
     ]
    }
   ],
   "source": [
    "# Mark the verbs for each of the former and later couplets\n",
    "couplet_30001_40000['Column1_Tag'] = couplet_30001_40000['Column1'].apply(tag_verbs_by_character)\n",
    "couplet_30001_40000['Column2_Tag'] = couplet_30001_40000['Column2'].apply(tag_verbs_by_character)\n",
    "\n",
    "# Print result\n",
    "print(couplet_30001_40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25a4af16-cf51-4c25-ba5d-dac14e867477",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet_30001_40000.to_csv('词性数据/couplet_30001_40000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f6677f5-2e5c-4104-be36-65519991f6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_200001_210000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_210001_220000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_220001_230000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_230001_240000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_240001_250000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_250001_260000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_260001_270000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_270001_280000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_280001_290000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_290001_300000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_300001_310000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_310001_320000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_320001_330000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_330001_340000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 词性数据/couplet_340001_344949.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17916\\2898550900.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n"
     ]
    }
   ],
   "source": [
    "# Setting the start and end indexes\n",
    "start_index = 200000  \n",
    "end_index = cleaned_couplet_4.shape[0]  # Total number of rows of data\n",
    "step = 10000  # Step size for each process\n",
    "\n",
    "for i in range(start_index, end_index, step):\n",
    "    # Dynamic generation of chunked data\n",
    "    chunk = cleaned_couplet_4.iloc[i:i + step]\n",
    "    \n",
    "    # Apply the tag_verbs_by_character Function\n",
    "    chunk['Column1_Tag'] = chunk['Column1'].apply(tag_verbs_by_character)\n",
    "    chunk['Column2_Tag'] = chunk['Column2'].apply(tag_verbs_by_character)\n",
    "    \n",
    "    # Dynamically generated file names\n",
    "    output_path = f'词性数据/couplet_{i + 1}_{min(i + step, end_index)}.csv'\n",
    "    \n",
    "    # Save data\n",
    "    chunk.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c1618-1023-4a07-9aea-ce1eed788ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69626bd-3423-475b-bb0c-5fc316f6d67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a90a6a2-d68a-40b6-923d-8b6f80e11766",
   "metadata": {},
   "source": [
    "# 5. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de152f62-bf89-48a6-8306-996545349e72",
   "metadata": {},
   "source": [
    "## 5.1. Define the Segmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8b03c257-7ed1-4f1b-b3b5-dbc83bd6e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Result: ['清华大学', '是', '一', '所', '著名', '的', '高等', '学府', '。']\n"
     ]
    }
   ],
   "source": [
    "# Input Sentences\n",
    "sentence = [\"清华大学是一所著名的高等学府。\"]\n",
    "\n",
    "# Segmentation using the pipeline method\n",
    "result = ltp.pipeline(sentence, tasks=[\"cws\"])  # Performing the Segmentation Task\n",
    "\n",
    "# Extracting Segmentation Results\n",
    "seg = result.cws[0]  # Get the result of the first sentence's disambiguation\n",
    "print(\"Segmentation Result:\", seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ad7209cb-bc28-47ea-a8b0-ecca06778a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining encoding functions\n",
    "def encode_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Sentences are segmented and coded:\n",
    "    The first word of each word is labeled 1 and the rest of the word is labeled 0.\n",
    "    \"\"\"\n",
    "    # Segmentation\n",
    "    result = ltp.pipeline([sentence], tasks=[\"cws\"])\n",
    "    seg = result.cws[0]  # Segmentation result\n",
    "\n",
    "    # Initialize the code list\n",
    "    #encoding = [0] * len(sentence)\n",
    "    encoding = [0] * 7 \n",
    "    ###\n",
    "    ### I've changed it directly to 7. If you want to run the following test code, change the encoding back to the one above.\n",
    "\n",
    "    # Iterate over the result of the word segmentation, marking the encoding\n",
    "    start_idx = 0\n",
    "    for word in seg:\n",
    "        # Mark the first Chinese character of the current expression as 1\n",
    "        encoding[start_idx] = 1\n",
    "        # Move the index position to skip the length of the current word\n",
    "        start_idx += len(word)\n",
    "    \n",
    "    # Converting a list of codes into a string\n",
    "    return ''.join(map(str, encoding))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e994e157-9bd7-4545-ae89-4524e8d3c987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码结果: 10001111011010\n"
     ]
    }
   ],
   "source": [
    "# example sentence\n",
    "sentence = \"清华大学是一所著名的高等学府\"\n",
    "\n",
    "# call function\n",
    "encoded = encode_sentence(sentence)\n",
    "print(\"Encoding results:\", encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "02df9d79-0dba-4315-a496-57fadec1cd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码结果: 1010101\n"
     ]
    }
   ],
   "source": [
    "# example sentence\n",
    "sentence = \"黄莺紫燕迎春使\"\n",
    "\n",
    "# call function\n",
    "encoded = encode_sentence(sentence)\n",
    "print(\"Encoding results:\", encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3316a9-db08-4238-a124-55bbb615ada5",
   "metadata": {},
   "source": [
    "## 5.2. Small batch run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "43e15d4e-84fb-4895-8ed5-2949660c1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet_0_10000 = cleaned_couplet_4.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ce4b95ec-2708-4c1b-a3f6-d2fe04b14c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Column1  Column2\n",
      "0     晚风摇树树还挺  晨露润花花更红\n",
      "1     愿景天成无墨迹  万方乐奏有于阗\n",
      "2     丹枫江冷人初去  绿柳堤新燕复来\n",
      "3     闲来野钓人稀处  兴起高歌酒醉中\n",
      "4     投石向天跟命斗  闭门问卷与时争\n",
      "...       ...      ...\n",
      "9995  无常最是风云变  淡定一如泰岳闲\n",
      "9996  泻玉吻梅香雪海  熔金落日醉春江\n",
      "9997  且凭鹤驾寻沧海  忍送文星上碧天\n",
      "9998  第一香应名士品  初三月是美人修\n",
      "9999  诗风到处生春景  禅趣来时悟妙机\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(couplet_0_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "19989064-178a-4bde-9ba9-f35781deac93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m couplet_0_10000[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn1_Tag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m couplet_0_10000[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(encode_sentence)\n\u001b[1;32m      2\u001b[0m couplet_0_10000[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn2_Tag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m couplet_0_10000[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(encode_sentence)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[125], line 8\u001b[0m, in \u001b[0;36mencode_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mSentences are segmented and coded:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mThe first word of each word is labeled 1 and the rest of the word is labeled 0.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Segmentation\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m ltp\u001b[38;5;241m.\u001b[39mpipeline([sentence], tasks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcws\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m seg \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcws[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Segmentation result\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize the code list\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ltp/nerual.py:24\u001b[0m, in \u001b[0;36mno_grad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ltp/nerual.py:155\u001b[0m, in \u001b[0;36mLTP.pipeline\u001b[0;34m(self, inputs, tasks, raw_format, return_dict)\u001b[0m\n\u001b[1;32m    152\u001b[0m     word_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tokenized\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 155\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbackbone(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    156\u001b[0m cache \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    157\u001b[0m hidden \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs,\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: word_index,\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: word_attention_mask,\n\u001b[1;32m    162\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:911\u001b[0m, in \u001b[0;36mElectraModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings_project\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    909\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_project(hidden_states)\n\u001b[0;32m--> 911\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    912\u001b[0m     hidden_states,\n\u001b[1;32m    913\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m    914\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    915\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m    916\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m    917\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    918\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    919\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    920\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    921\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    922\u001b[0m )\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:583\u001b[0m, in \u001b[0;36mElectraEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    572\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    573\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    574\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m         output_attentions,\n\u001b[1;32m    581\u001b[0m     )\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    584\u001b[0m         hidden_states,\n\u001b[1;32m    585\u001b[0m         attention_mask,\n\u001b[1;32m    586\u001b[0m         layer_head_mask,\n\u001b[1;32m    587\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    588\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    589\u001b[0m         past_key_value,\n\u001b[1;32m    590\u001b[0m         output_attentions,\n\u001b[1;32m    591\u001b[0m     )\n\u001b[1;32m    593\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/electra/modeling_electra.py:514\u001b[0m, in \u001b[0;36mElectraLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    511\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    512\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 514\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[1;32m    516\u001b[0m )\n\u001b[1;32m    517\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pytorch_utils.py:225\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_tensors) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_tensors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has to be a tuple/list of tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# inspect.signature exist since python 3.5 and is a python method -> no problem with backward compatibility\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m num_args_in_forward_chunk_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inspect\u001b[38;5;241m.\u001b[39msignature(forward_fn)\u001b[38;5;241m.\u001b[39mparameters)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_args_in_forward_chunk_fn \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_tensors):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward_chunk_fn expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_args_in_forward_chunk_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m arguments, but only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensors are given\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/inspect.py:3341\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3340\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Signature\u001b[38;5;241m.\u001b[39mfrom_callable(obj, follow_wrapped\u001b[38;5;241m=\u001b[39mfollow_wrapped,\n\u001b[1;32m   3342\u001b[0m                                    \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/inspect.py:3081\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3077\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   3078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   3079\u001b[0m                   follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_callable(obj, sigcls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   3082\u001b[0m                                     follow_wrapper_chains\u001b[38;5;241m=\u001b[39mfollow_wrapped,\n\u001b[1;32m   3083\u001b[0m                                     \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/inspect.py:2523\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a callable object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj))\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mMethodType):\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;66;03m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m     \u001b[38;5;66;03m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[0;32m-> 2523\u001b[0m     sig \u001b[38;5;241m=\u001b[39m _get_signature_of(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m)\n\u001b[1;32m   2525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_bound_arg:\n\u001b[1;32m   2526\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _signature_bound_method(sig)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/inspect.py:2593\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2588\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[1;32m   2590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2591\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2592\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[1;32m   2594\u001b[0m                                     skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg,\n\u001b[1;32m   2595\u001b[0m                                     \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2599\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/inspect.py:2483\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(Parameter(name, annotation\u001b[38;5;241m=\u001b[39mannotation,\n\u001b[1;32m   2479\u001b[0m                                 kind\u001b[38;5;241m=\u001b[39m_VAR_KEYWORD))\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;66;03m# Is 'func' is a pure Python function - don't validate the\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# parameters list (for correct order and defaults), it should be OK.\u001b[39;00m\n\u001b[0;32m-> 2483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(parameters,\n\u001b[1;32m   2484\u001b[0m            return_annotation\u001b[38;5;241m=\u001b[39mannotations\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m'\u001b[39m, _empty),\n\u001b[1;32m   2485\u001b[0m            __validate_parameters__\u001b[38;5;241m=\u001b[39mis_duck_function)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/inspect.py:3072\u001b[0m, in \u001b[0;36mSignature.__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m   3070\u001b[0m             params[name] \u001b[38;5;241m=\u001b[39m param\n\u001b[1;32m   3071\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3072\u001b[0m         params \u001b[38;5;241m=\u001b[39m OrderedDict((param\u001b[38;5;241m.\u001b[39mname, param) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m parameters)\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mMappingProxyType(params)\n\u001b[1;32m   3075\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_annotation \u001b[38;5;241m=\u001b[39m return_annotation\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/inspect.py:3072\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3070\u001b[0m             params[name] \u001b[38;5;241m=\u001b[39m param\n\u001b[1;32m   3071\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3072\u001b[0m         params \u001b[38;5;241m=\u001b[39m OrderedDict((param\u001b[38;5;241m.\u001b[39mname, param) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m parameters)\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mMappingProxyType(params)\n\u001b[1;32m   3075\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_annotation \u001b[38;5;241m=\u001b[39m return_annotation\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "couplet_0_10000['Column1_Tag'] = couplet_0_10000['Column1'].apply(encode_sentence)\n",
    "couplet_0_10000['Column2_Tag'] = couplet_0_10000['Column2'].apply(encode_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "537c2d19-85bd-4929-a9d3-30c77a987f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Column1  Column2 Column1_Tag Column2_Tag\n",
      "0     晚风摇树树还挺  晨露润花花更红     1011111     1011011\n",
      "1     愿景天成无墨迹  万方乐奏有于阗     1101110     1001111\n",
      "2     丹枫江冷人初去  绿柳堤新燕复来     1001111     1001011\n",
      "3     闲来野钓人稀处  兴起高歌酒醉中     1111111     1010101\n",
      "4     投石向天跟命斗  闭门问卷与时争     1111111     1000111\n",
      "...       ...      ...         ...         ...\n",
      "9995  无常最是风云变  淡定一如泰岳闲     1011100     1011101\n",
      "9996  泻玉吻梅香雪海  熔金落日醉春江     1101111     1010110\n",
      "9997  且凭鹤驾寻沧海  忍送文星上碧天     1111110     1111110\n",
      "9998  第一香应名士品  初三月是美人修     1011110     1001100\n",
      "9999  诗风到处生春景  禅趣来时悟妙机     1010110     1011110\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(couplet_0_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aab69658-55f9-4697-8b69-c6eea4a8cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet_0_10000.to_csv('分词数据/couplet_0_10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f611645-366b-4791-92c0-38fd9cac3683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b91487b0-0600-4954-b041-77b0a15f6859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_130001_140000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_140001_150000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_150001_160000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_160001_170000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_170001_180000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_180001_190000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_190001_200000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_200001_210000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_210001_220000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_220001_230000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_230001_240000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_240001_250000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_250001_260000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_260001_270000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_270001_280000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_280001_290000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_290001_300000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_300001_310000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_310001_320000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_320001_330000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_330001_340000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 分词数据/分词couplet_340001_344949.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_2340\\207615539.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n"
     ]
    }
   ],
   "source": [
    "# Setting the start and end indexes\n",
    "start_index = 130000  \n",
    "end_index = cleaned_couplet_4.shape[0]  # Total number of rows of data\n",
    "step = 10000  # Step size for each process\n",
    "\n",
    "for i in range(start_index, end_index, step):\n",
    "    # Dynamic generation of chunked data\n",
    "    chunk = cleaned_couplet_4.iloc[i:i + step]\n",
    "    \n",
    "    # Applying the tag_verbs_by_character Function\n",
    "    chunk['Column1_Tag'] = chunk['Column1'].apply(encode_sentence)\n",
    "    chunk['Column2_Tag'] = chunk['Column2'].apply(encode_sentence)\n",
    "    \n",
    "    # Dynamically generated file names\n",
    "    output_path = f'分词数据/分词couplet_{i + 1}_{min(i + step, end_index)}.csv'\n",
    "    \n",
    "    # Save data\n",
    "    chunk.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9478b-51f4-4e47-ac43-2f8abf0aa2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
