{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Load and preprocess data\n",
    "def parse_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) > 2:\n",
    "                theme = parts[0].split('#')\n",
    "                emotions = parts[1].split('#')\n",
    "                poetry = ','.join(parts[2:]).strip()\n",
    "                data.append({\"theme\": theme, \"emotions\": emotions, \"poetry\": poetry})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Specify file path\n",
    "file_path = 'C:\\\\Users\\\\86152\\\\Desktop\\\\Classical Chinese poetry_with_labels.txt'\n",
    "data = parse_file(file_path)\n",
    "\n",
    "# Extract unique themes and emotions\n",
    "themes = set(theme for sublist in data['theme'] for theme in sublist)\n",
    "emotions = set(emotion for sublist in data['emotions'] for emotion in sublist)\n",
    "\n",
    "# Initialize Multi-Label Binarizers\n",
    "theme_binarizer = MultiLabelBinarizer().fit(data['theme'])\n",
    "emotion_binarizer = MultiLabelBinarizer().fit(data['emotions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, theme_binarizer, emotion_binarizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.theme_binarizer = theme_binarizer\n",
    "        self.emotion_binarizer = emotion_binarizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        poetry = self.data.iloc[index]['poetry']\n",
    "        themes = self.theme_binarizer.transform([self.data.iloc[index]['theme']])[0]\n",
    "        emotions = self.emotion_binarizer.transform([self.data.iloc[index]['emotions']])[0]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            poetry,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'theme_labels': torch.tensor(themes, dtype=torch.float),\n",
    "            'emotion_labels': torch.tensor(emotions, dtype=torch.float),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"C:\\\\Users\\\\86152\\\\.cache\\\\huggingface\\\\hub\\\\models--SIKU-BERT--sikubert\\\\snapshots\\\\fc656de2d6bde33919102dd3abe31c843f42226a\")\n",
    "\n",
    "# Set parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "train_dataset = PoetryDataset(data, tokenizer, MAX_LEN, theme_binarizer, emotion_binarizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelBERT(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_theme_labels, num_emotion_labels):\n",
    "        super(MultiLabelBERT, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(model_name, num_labels=0)  # Base BERT without predefined labels\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.theme_classifier = torch.nn.Linear(self.bert.config.hidden_size, num_theme_labels)\n",
    "        self.emotion_classifier = torch.nn.Linear(self.bert.config.hidden_size, num_emotion_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.dropout(outputs[1])  # CLS token\n",
    "\n",
    "        theme_logits = self.theme_classifier(pooled_output)\n",
    "        emotion_logits = self.emotion_classifier(pooled_output)\n",
    "        return theme_logits, emotion_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        theme_labels = batch['theme_labels'].to(device)\n",
    "        emotion_labels = batch['emotion_labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        theme_logits, emotion_logits = model(input_ids, attention_mask)\n",
    "\n",
    "        theme_loss = loss_fn(theme_logits, theme_labels)\n",
    "        emotion_loss = loss_fn(emotion_logits, emotion_labels)\n",
    "        loss = theme_loss + emotion_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\86152\\.cache\\huggingface\\hub\\models--SIKU-BERT--sikubert\\snapshots\\fc656de2d6bde33919102dd3abe31c843f42226a and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3645\n",
      "Epoch 2/5, Loss: 0.2108\n",
      "Epoch 3/5, Loss: 0.1552\n",
      "Epoch 4/5, Loss: 0.1167\n",
      "Epoch 5/5, Loss: 0.0900\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiLabelBERT(\"C:\\\\Users\\\\86152\\\\.cache\\\\huggingface\\\\hub\\\\models--SIKU-BERT--sikubert\\\\snapshots\\\\fc656de2d6bde33919102dd3abe31c843f42226a\", len(theme_binarizer.classes_), len(emotion_binarizer.classes_))\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and Loss\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss = train(model, train_dataloader, optimizer, loss_fn, device)\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, text, theme_binarizer, emotion_binarizer, device):\n",
    "    # Tokenize and move inputs to the same device as the model\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=MAX_LEN,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        theme_logits, emotion_logits = model(\n",
    "            encoding['input_ids'],\n",
    "            encoding['attention_mask']\n",
    "        )\n",
    "        themes = (torch.sigmoid(theme_logits) > 0.5).cpu().numpy()\n",
    "        emotions = (torch.sigmoid(emotion_logits) > 0.5).cpu().numpy()\n",
    "\n",
    "    return theme_binarizer.inverse_transform(themes), emotion_binarizer.inverse_transform(emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Themes: [('战争',)]\n",
      "Emotions: [('想家',)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"送胡昌世比部转饷辽阳便道归五岭,夜夜旄头照海天，辽阳杀气镇相缠。枕戈谁念三军苦，转饷俄腾万灶烟。塞雪近关看破腊，岭梅迎马报新年。相如拥传多光彩，岂羡乘槎到日边。。\"\n",
    "themes, emotions = predict(model, tokenizer, text, theme_binarizer, emotion_binarizer, device)\n",
    "print(f\"Themes: {themes}\")\n",
    "print(f\"Emotions: {emotions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sen1: [('咏物',)]&[()]\n",
      "Sen2: [()]&[()]\n"
     ]
    }
   ],
   "source": [
    "sen1 = '红梅映雪千家瑞'\n",
    "sen2 = '赤县迎春百业新'\n",
    "themes1, emotions1 = predict(model, tokenizer, sen1, theme_binarizer, emotion_binarizer, device)\n",
    "themes2, emotions2 = predict(model, tokenizer, sen2, theme_binarizer, emotion_binarizer, device)\n",
    "print(f\"Sen1: {themes1}&{emotions1}\")\n",
    "print(f\"Sen2: {themes2}&{emotions2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, text, theme_binarizer, emotion_binarizer, device):\n",
    "    # Tokenize and move inputs to the same device as the model\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=MAX_LEN,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        theme_logits, emotion_logits = model(\n",
    "            encoding['input_ids'],\n",
    "            encoding['attention_mask']\n",
    "        )\n",
    "        # Select the class with the largest probability\n",
    "        theme_index = torch.argmax(theme_logits, dim=-1).cpu().numpy()\n",
    "        emotion_index = torch.argmax(emotion_logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    # Map indices back to labels using binarizer's classes\n",
    "    themes = [theme_binarizer.classes_[idx] for idx in theme_index]\n",
    "    emotions = [emotion_binarizer.classes_[idx] for idx in emotion_index]\n",
    "\n",
    "    return themes, emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_in = ['红梅映雪千家瑞','花明柳媚春光好','水无两点不成冰','庄生梦蝶知无我','秋风送爽花正艳','黄河东去流不息','浪遏飞舟留客住','黄莺日日盼新岁']\n",
    "sen_out = ['赤县迎春百业新','大江南北庆丰收','王不出头谁是主','晏子分桃为有他','雨打屋檐人未归','庭前落叶扫无痕','风吹垂柳赋情来','绿柳枝枝辞旧年']\n",
    "theme_in = []\n",
    "theme_out = []\n",
    "emotion_in = []\n",
    "emotion_out = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sen_in)):\n",
    "    sen1 = sen_in[i]\n",
    "    sen2 = sen_out[i]\n",
    "    theme1, emotion1 = predict(model, tokenizer, sen1, theme_binarizer, emotion_binarizer, device)\n",
    "    theme2, emotion2 = predict(model, tokenizer, sen2, theme_binarizer, emotion_binarizer, device)\n",
    "    theme_in.append(theme1)\n",
    "    emotion_in.append(emotion1)\n",
    "    theme_out.append(theme2)\n",
    "    emotion_out.append(emotion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'in': sen_in, 'out': sen_out, 'theme_in': theme_in, 'theme_out': theme_out, 'emotion_in':emotion_in, 'emotion_out':emotion_out}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "      <th>theme_in</th>\n",
       "      <th>theme_out</th>\n",
       "      <th>emotion_in</th>\n",
       "      <th>emotion_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>红梅映雪千家瑞</td>\n",
       "      <td>赤县迎春百业新</td>\n",
       "      <td>[咏物]</td>\n",
       "      <td>[怀古]</td>\n",
       "      <td>[想家]</td>\n",
       "      <td>[喜悦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>花明柳媚春光好</td>\n",
       "      <td>大江南北庆丰收</td>\n",
       "      <td>[咏物]</td>\n",
       "      <td>[思乡]</td>\n",
       "      <td>[想家]</td>\n",
       "      <td>[喜悦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>水无两点不成冰</td>\n",
       "      <td>王不出头谁是主</td>\n",
       "      <td>[咏物]</td>\n",
       "      <td>[战争]</td>\n",
       "      <td>[喜悦]</td>\n",
       "      <td>[喜悦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>庄生梦蝶知无我</td>\n",
       "      <td>晏子分桃为有他</td>\n",
       "      <td>[怀古]</td>\n",
       "      <td>[怀古]</td>\n",
       "      <td>[喜悦]</td>\n",
       "      <td>[失意]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>秋风送爽花正艳</td>\n",
       "      <td>雨打屋檐人未归</td>\n",
       "      <td>[送别]</td>\n",
       "      <td>[田园]</td>\n",
       "      <td>[想家]</td>\n",
       "      <td>[想家]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>黄河东去流不息</td>\n",
       "      <td>庭前落叶扫无痕</td>\n",
       "      <td>[思乡]</td>\n",
       "      <td>[咏物]</td>\n",
       "      <td>[想家]</td>\n",
       "      <td>[喜悦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>浪遏飞舟留客住</td>\n",
       "      <td>风吹垂柳赋情来</td>\n",
       "      <td>[咏物]</td>\n",
       "      <td>[咏物]</td>\n",
       "      <td>[喜悦]</td>\n",
       "      <td>[喜悦]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>黄莺日日盼新岁</td>\n",
       "      <td>绿柳枝枝辞旧年</td>\n",
       "      <td>[咏物]</td>\n",
       "      <td>[咏物]</td>\n",
       "      <td>[喜悦]</td>\n",
       "      <td>[想家]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        in      out theme_in theme_out emotion_in emotion_out\n",
       "0  红梅映雪千家瑞  赤县迎春百业新     [咏物]      [怀古]       [想家]        [喜悦]\n",
       "1  花明柳媚春光好  大江南北庆丰收     [咏物]      [思乡]       [想家]        [喜悦]\n",
       "2  水无两点不成冰  王不出头谁是主     [咏物]      [战争]       [喜悦]        [喜悦]\n",
       "3  庄生梦蝶知无我  晏子分桃为有他     [怀古]      [怀古]       [喜悦]        [失意]\n",
       "4  秋风送爽花正艳  雨打屋檐人未归     [送别]      [田园]       [想家]        [想家]\n",
       "5  黄河东去流不息  庭前落叶扫无痕     [思乡]      [咏物]       [想家]        [喜悦]\n",
       "6  浪遏飞舟留客住  风吹垂柳赋情来     [咏物]      [咏物]       [喜悦]        [喜悦]\n",
       "7  黄莺日日盼新岁  绿柳枝枝辞旧年     [咏物]      [咏物]       [喜悦]        [想家]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "desktop = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "file_path = os.path.join(desktop, \"theme_emotion.csv\")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sen1: ['咏物']&['想家']\n",
      "Sen2: ['怀古']&['喜悦']\n"
     ]
    }
   ],
   "source": [
    "sen1 = '红梅映雪千家瑞'\n",
    "sen2 = '赤县迎春百业新'\n",
    "themes1, emotions1 = predict(model, tokenizer, sen1, theme_binarizer, emotion_binarizer, device)\n",
    "themes2, emotions2 = predict(model, tokenizer, sen2, theme_binarizer, emotion_binarizer, device)\n",
    "print(f\"Sen1: {themes1}&{emotions1}\")\n",
    "print(f\"Sen2: {themes2}&{emotions2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sen1: ['思乡']&['想家']\n",
      "Sen2: ['咏物']&['喜悦']\n"
     ]
    }
   ],
   "source": [
    "sen3 = '黄河东去流不息'\n",
    "sen4 = '庭前落叶扫无痕'\n",
    "themes3, emotions3 = predict(model, tokenizer, sen3, theme_binarizer, emotion_binarizer, device)\n",
    "themes4, emotions4 = predict(model, tokenizer, sen4, theme_binarizer, emotion_binarizer, device)\n",
    "print(f\"Sen1: {themes3}&{emotions3}\")\n",
    "print(f\"Sen2: {themes4}&{emotions4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
